# Prometheus Helm Chart Values for NeuroLake
# Use with: helm install prometheus prometheus-community/kube-prometheus-stack -f prometheus-values.yaml

# Global settings
global:
  rbac:
    create: true

# Prometheus Operator
prometheusOperator:
  enabled: true

  # Resource limits
  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi

  # Admission webhooks
  admissionWebhooks:
    enabled: true
    patch:
      enabled: true

# Prometheus Server
prometheus:
  enabled: true

  # Service configuration
  prometheusSpec:
    # Replica count for HA
    replicas: 2

    # Retention period
    retention: 30d
    retentionSize: "50GB"

    # Storage
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
          # storageClassName: "fast-ssd"  # Uncomment and specify storage class

    # Resources
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 8Gi

    # Service monitors - automatically discover targets
    serviceMonitorSelector:
      matchLabels:
        prometheus: neurolake

    # Pod monitors
    podMonitorSelector:
      matchLabels:
        prometheus: neurolake

    # Rule selector
    ruleSelector:
      matchLabels:
        prometheus: neurolake

    # External labels
    externalLabels:
      cluster: neurolake-production
      environment: production

    # Additional scrape configs
    additionalScrapeConfigs:
      # Scrape NeuroLake API metrics
      - job_name: 'neurolake-api'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - neurolake
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
            action: keep
            regex: api
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

      # Scrape PostgreSQL metrics (if pg_exporter is installed)
      - job_name: 'postgres'
        static_configs:
          - targets: ['postgres-exporter.neurolake.svc:9187']

      # Scrape Redis metrics (if redis_exporter is installed)
      - job_name: 'redis'
        static_configs:
          - targets: ['redis-exporter.neurolake.svc:9121']

      # Scrape MinIO metrics
      - job_name: 'minio'
        metrics_path: /minio/v2/metrics/cluster
        static_configs:
          - targets: ['minio.neurolake.svc:9000']

# Grafana
grafana:
  enabled: true

  # Admin credentials (CHANGE THESE!)
  adminPassword: "admin"  # Change this in production!

  # Persistence
  persistence:
    enabled: true
    size: 10Gi
    # storageClassName: "default"

  # Resources
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi

  # Ingress
  ingress:
    enabled: false  # Enable if needed
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - grafana.neurolake.example.com
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.neurolake.example.com

  # Datasources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-kube-prometheus-prometheus:9090
          access: proxy
          isDefault: true
          jsonData:
            timeInterval: 30s

  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default

  # Pre-configured dashboards
  dashboards:
    default:
      # Kubernetes cluster monitoring
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus

      # Node exporter
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus

      # PostgreSQL
      postgresql:
        gnetId: 9628
        revision: 7
        datasource: Prometheus

      # Redis
      redis:
        gnetId: 11835
        revision: 1
        datasource: Prometheus

# Alertmanager
alertmanager:
  enabled: true

  # Replica count
  alertmanagerSpec:
    replicas: 2

    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    # Resources
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

  # Configuration
  config:
    global:
      resolve_timeout: 5m
      slack_api_url: ''  # Add your Slack webhook URL

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
        # Critical alerts
        - match:
            severity: critical
          receiver: 'critical'
          continue: true

        # Warning alerts
        - match:
            severity: warning
          receiver: 'warning'

    receivers:
      - name: 'default'
        # webhook_configs:
        #   - url: 'http://alertmanager-webhook-receiver:8080/webhook'

      - name: 'critical'
        # Slack notification for critical alerts
        # slack_configs:
        #   - channel: '#alerts-critical'
        #     title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        #     text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

        # PagerDuty integration
        # pagerduty_configs:
        #   - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'

      - name: 'warning'
        # Slack notification for warnings
        # slack_configs:
        #   - channel: '#alerts-warning'
        #     title: 'Warning: {{ .GroupLabels.alertname }}'
        #     text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'cluster', 'service']

# Node Exporter
nodeExporter:
  enabled: true

  # Resources
  resources:
    requests:
      cpu: 100m
      memory: 30Mi
    limits:
      cpu: 200m
      memory: 50Mi

# Kube State Metrics
kubeStateMetrics:
  enabled: true

  # Resources
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 64Mi

# Prometheus Node Exporter
prometheus-node-exporter:
  resources:
    requests:
      cpu: 100m
      memory: 30Mi
    limits:
      cpu: 200m
      memory: 50Mi

# Service Monitors
additionalServiceMonitors:
  # Monitor NGINX Ingress
  - name: nginx-ingress
    selector:
      matchLabels:
        app.kubernetes.io/name: ingress-nginx
    endpoints:
      - port: metrics
        interval: 30s

# Prometheus Rules (Alerts)
additionalPrometheusRulesMap:
  neurolake-alerts:
    groups:
      # API Alerts
      - name: neurolake-api
        interval: 30s
        rules:
          - alert: HighAPIErrorRate
            expr: |
              sum(rate(http_requests_total{job="neurolake-api",status=~"5.."}[5m]))
              /
              sum(rate(http_requests_total{job="neurolake-api"}[5m]))
              > 0.05
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High API error rate"
              description: "API error rate is {{ $value | humanizePercentage }} (threshold: 5%)"

          - alert: HighAPILatency
            expr: |
              histogram_quantile(0.95,
                sum(rate(http_request_duration_seconds_bucket{job="neurolake-api"}[5m])) by (le)
              ) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High API latency"
              description: "API p95 latency is {{ $value }}s (threshold: 1s)"

          - alert: APIDown
            expr: up{job="neurolake-api"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "API is down"
              description: "NeuroLake API has been down for more than 1 minute"

      # Database Alerts
      - name: database
        interval: 30s
        rules:
          - alert: HighDatabaseConnectionUsage
            expr: |
              pg_stat_database_numbackends / pg_settings_max_connections > 0.8
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High database connection usage"
              description: "Database connection usage is {{ $value | humanizePercentage }}"

          - alert: DatabaseDown
            expr: up{job="postgres"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Database is down"
              description: "PostgreSQL has been down for more than 1 minute"

      # Resource Alerts
      - name: resources
        interval: 30s
        rules:
          - alert: HighMemoryUsage
            expr: |
              (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage on {{ $labels.instance }}"
              description: "Memory usage is {{ $value | humanizePercentage }}"

          - alert: HighCPUUsage
            expr: |
              100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage on {{ $labels.instance }}"
              description: "CPU usage is {{ $value }}%"

          - alert: DiskSpaceLow
            expr: |
              (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Low disk space on {{ $labels.instance }}"
              description: "Disk space is {{ $value | humanizePercentage }} full"

      # Pod Alerts
      - name: pods
        interval: 30s
        rules:
          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod {{ $labels.pod }} is crash looping"
              description: "Pod has restarted {{ $value }} times in the last 15 minutes"

          - alert: PodNotReady
            expr: |
              sum by (namespace, pod) (kube_pod_status_phase{phase!~"Running|Succeeded"}) > 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod {{ $labels.pod }} is not ready"
              description: "Pod has been in {{ $labels.phase }} phase for more than 5 minutes"
